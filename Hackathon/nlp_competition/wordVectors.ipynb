{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "'''\n",
    "Once completed running this script will generate and save the word vectors \n",
    "in a pickle file.\n",
    "'''\n",
    "\n",
    "'''\n",
    "You want texts to be a 2 dimensional list.  Each list should be a sentence.\n",
    "Each sentence should be represented as a list of words.  The more sentences\n",
    "in texts the better and broader word vectors you will get.\n",
    "\n",
    "Some functions that will be useful:\n",
    "open('FILEPATH','r') Returns the file stored at the relative 'FILEPATH'\n",
    "\t\t\t\t\t in a format that can be read.\n",
    "json.load(file)      Returns the parsed contents of a file.\n",
    "sent_tokenize(text)  Accepts a string that contains some number of sentences.  \n",
    "\t\t\t\t\t Returns a list where each element is a sentence from \n",
    "\t\t\t\t\t text in order.\n",
    "word_tokenize(text)  Accepts a string that contains some number of words.\n",
    "\t\t\t\t\t Returns a list where each element is a word from the\n",
    "\t\t\t\t\t text in order.\n",
    "sum(listOfLists, []) Concatenates and returns lists in listsOfLists.\n",
    "\n",
    "Feel free to mess around with these functions in the terminal to understand\n",
    "better what they do.'''\n",
    "\n",
    "#CODE HERE\n",
    "file = open('testDataSet.json','r')\n",
    "text = json.load(file) \n",
    "l = []\n",
    "for i in text:\n",
    "    a = sent_tokenize(i.get('review_text'))\n",
    "    b = []\n",
    "    for j in a:\n",
    "        b.append(word_tokenize(j))\n",
    "    l.append(b)\n",
    "texts = sum(l, [])\n",
    "\n",
    "'''\n",
    "The dimensionality of your word vectors.  This is more of a judgement call.\n",
    "You want to make it large enough where it's sufficiently expressive and small\n",
    "enough where it's not excessive.  Remember the idea of wordVectors is to build\n",
    "a rich numerical representation of words.\n",
    "'''\n",
    "wordVecDim = 100\n",
    "\n",
    "'''\n",
    "Word2Vec is a popular algorithm that learns word vectors based on contextual\n",
    "relationships.  Feel free to read more online about how the model works.  But\n",
    "all you need to know for this project is that they will allow you to represent\n",
    "a word as a numerical vector of dimension 'size'.\n",
    "'''\n",
    "wordVectors = Word2Vec(sentences=sum(texts,[]), size=wordVecDim).wv\n",
    "\n",
    "#Save the word vectors and dimensionality to be used later\n",
    "pickle.dump((wordVectors, wordVecDim),open('wv.pkl','wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
